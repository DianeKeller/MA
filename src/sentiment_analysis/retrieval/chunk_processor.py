"""
chunk_processor.py
------------------
Version 1.0, updated on 2024-12-25

"""

from logger import Logger
from src.sentiment_analysis.prompt_engineering.prompt_engineer_factory \
    import get_prompt_engineer
from src.data_structures.dictionary_chunker import DictionaryChunker
from src.data_structures.my_data_frame import MyDataFrame
from src.data_structures.my_dataframe_factory import MyDataFrameFactory
from src.decorators.data_check_decorators import parameters_not_empty
from src.decorators.type_check_decorators import enforce_input_types
from src.logging_mixin import LoggingMixin
from src.sentiment_analysis.retrieval.custom_exceptions import \
    BatchFinishedException, ChunkFinishedException, CriticalException
from src.sentiment_analysis.retrieval.query_column_processor import \
    QueryColumnProcessor
from src.sentiment_analysis.sentiment_analysis_config import \
    SentimentAnalysisConfig
from src.utils.data_utils import is_none_or_empty
from type_aliases import PromptsDictType


class ChunkProcessor(LoggingMixin):
    """
    ChunkProcessor class.

    This class provides the attributes and methods for the processing of
    chunks of the prompts collection.

    The multiple prompts generated are divided in smaller collections
    of variants so that ideally, one chunk can be processed and sent to the
    LLM's API before the Hugging Face rate limit hits.

    Attributes
    ----------
    language : str
        The language of the samples.

    samples : MyDataFrame
        The batch samples to process.

    all_prompts : PromptsDictType
        All prompts generated by the PromptEngineer.

    chunk : PromptsDictType | None
        The current chunk being processed.

    chunk_nr : int
        The current chunk number.

    chunk_samples : MyDataFrame
        The chunk_samples to process in batches.

    chunk_size : int
        The size of each chunk, according to the sentiment analysis
        configuration.

    iterator_counter : int
        Tracks the number of queries processed.

    queries_chunker : DictionaryChunker | None
        The queries chunker.

    skip_chunker : bool
        A flag indicating whether to skip the chunk generation in
        the current iteration.


    Methods
    -------
    process_chunk(chunk: PromptsDictType) -> None:
        Processes the given chunk.

    process_chunks() -> MyDataFrame:
        Gets the chunks and processes them iteratively.

    """

    @parameters_not_empty()
    @enforce_input_types
    def __init__(
            self,
            language: str,
            batch_samples: MyDataFrame
    ):
        """
        Constructor.

        Initializes the ChunkProcessor instance.

        Parameters
        ----------
        language : str
            The language of the samples.

        batch_samples : MyDataFrame
            The batch samples to process.

        """

        # Override the default logger of the 'LoggingMixin' class.
        self._chunk_samples: MyDataFrame | None = None
        self._samples: MyDataFrame | None = None
        self._queries_chunker = None

        # Override the default logger of the 'LoggingMixin' class.
        self.logger = Logger(self.__class__.__name__).get_logger()

        self.language: str = language
        self.samples: MyDataFrame = batch_samples

        self.chunk: PromptsDictType | None = None
        self.chunk_nr: int = 0
        self.iterator_counter: int = 1
        self.skip_chunker: bool = False

        # Configs used in this class
        self.config = SentimentAnalysisConfig()
        strategy_nr = int(self.config.get('version'))

        # ATTENTION: The PromptEngineeringStrategy changes the config settings.
        # If things do not work as expected, check if the config returns the
        # wrong settings.

        self.prompt_engineer = get_prompt_engineer(strategy_nr)

        self.chunk_size: int = self.config.get('chunk_size')

        try:
            self.all_prompts: PromptsDictType = (
                self.prompt_engineer.get_prompts()
            )
            msg = "All %d prompts loaded!" % len(self.all_prompts)
            self._log(msg, 'info')

        except Exception as err:
            raise CriticalException(
                self.logger,
                "Could not find validated prompts. Ensure you run prompt "
                "engineering before attempting to retrieve sentiments from "
                "the LLM."
            ) from err

    # region --- Properties
    @property
    def samples(self) \
            -> MyDataFrame:
        """
        Gets the samples to process in batches.
        """

        if self._samples is None:
            return MyDataFrameFactory.create()

        return self._samples

    @samples.setter
    def samples(self, samples: MyDataFrame) \
            -> None:
        """
        Sets the samples to process in batches.
        """

        self._samples = samples

    @property
    def chunk_nr(self) \
            -> int:
        """
        Gets the chunk number.
        """

        if self._chunk_nr == 0:
            self._set_chunk_nr()

        return self._chunk_nr

    @chunk_nr.setter
    def chunk_nr(self, chunk_nr: int) \
            -> None:
        """
        Sets the chunk number.
        """

        self._chunk_nr = chunk_nr

    @property
    def chunk_samples(self) \
            -> MyDataFrame:
        """
        Gets the chunk_samples to process in batches.
        """

        if self._chunk_samples is None:
            return MyDataFrameFactory.create()

        return self._chunk_samples

    @chunk_samples.setter
    def chunk_samples(self, chunk_samples: MyDataFrame) \
            -> None:
        """
        Sets the chunk_samples to process in batches.
        """

        self._chunk_samples = chunk_samples

    @property
    def queries_chunker(self) \
            -> DictionaryChunker | None:
        """
        Gets the queries chunker.
        """

        if self._queries_chunker is None:
            self._set_queries_chunker()

        return self._queries_chunker

    @queries_chunker.setter
    def queries_chunker(self, queries_chunker: DictionaryChunker) \
            -> None:
        """
        Sets the queries chunker.
        """

        self._queries_chunker = queries_chunker

    # endregion --- Properties

    # region --- Public Methods

    def process_chunks(self) \
            -> MyDataFrame:
        """
        Gets the chunks and processes them.
        
        In a loop, asks the queries_chunker to return a chunk and 
        calls the process_chunk method to process the chunk.
        
        Returns
        -------
        MyDataFrame 
            The chunk samples with all the query and answer columns added.

        Notes
        -----
        The queries chunker iteratively produces chunks and manages the 
        corresponding checkpoint.
        
        """

        while True:

            if not self.skip_chunker:
                try:
                    self._generate_chunk()
                except BatchFinishedException as err:
                    raise BatchFinishedException(err) from err

            else:
                # After skipping the chunker reset the skip_chunker property
                # to False
                self.skip_chunker = False

            if not self.chunk:
                break

            self.process_chunk(self.chunk)

        return self.chunk_samples

    def process_chunk(self, chunk: PromptsDictType) \
            -> None:
        """
        Processes the given chunk.
        
        Uses the chunk to add query columns to the batch samples by calling 
        the _get_chunk_samples method. The resulting chunk samples are then 
        passed to a QueryColumnProcessor instance which will process the 
        query columns.
        
        Parameters
        ----------
        chunk : PromptsDictType
            The current chunk of prompt parts sets needed to generate the 
            query columns.

        Notes
        -----
        If this method passes a newly created chunk to the
        QueryColumnProcessor, this will raise a ChunkFinishedException,
        because the current results DataFrame's columns do not match the
        query numbers of the new chunk. Therefore, when catching this
        exception and returning to the process_chunks method, the generation
        of yet another chunk must be prevented. This is done with the
        skip_chunker boolean variable.

        """

        try:
            self.chunk_samples = self._get_chunk_samples(chunk)

            # Save the DataFrame with the chunk_samples so that at least the
            # queries are saved, even if they produce no valid answers at
            # all in the chunk.
            self.chunk_samples.save()

            query_column_processor = QueryColumnProcessor(
                self.language,
                self.chunk_samples,
                self.iterator_counter - self.chunk_size + 1
            )
            query_column_processor.process_query_columns()

        except ChunkFinishedException:
            self.skip_chunker = True
            self.chunk_nr = int(
                self.iterator_counter / self.chunk_size)

        except Exception as err:
            # Log and handle unexpected errors
            chunk_nr = int(self.iterator_counter / self.chunk_size)
            self._log(
                "Error processing chunk %d: %s" % (chunk_nr, err), 'error'
            )
            raise

    # endregion --- Public Methods

    # region --- Protected Methods
    def _generate_chunk(self) \
            -> None:
        """
        Generates the next chunk of prompts and stores it as a property.

        Sets the chunk and the iterator_counter properties.
        """

        msg = f"Generating new chunk. Current chunk: {self.chunk_nr}"
        self._log(msg, 'info')

        self.chunk, self.iterator_counter = (
            self.queries_chunker.get_next_chunk()
        )

        if is_none_or_empty(self.chunk):
            msg = "All chunks processed!"
            self._log(msg, 'info')
            raise BatchFinishedException(msg)

        msg = (
            f"New chunk: {self.chunk_nr} ({list(self.chunk.keys())[0]}"
            f"-{list(self.chunk.keys())[len(self.chunk) - 1]})"
        )
        self._log(msg, 'info')

    def _set_queries_chunker(self) \
            -> None:
        """
        Splits the prompts in chunks of 15 variants.

        Notes
        -----
        15 queries for 100 samples is the number of queries wich will pass
        before the Hugging Face rate limit hits.

        """

        self.queries_chunker = DictionaryChunker(
            self.all_prompts,
            self.chunk_size,
            f"{self.samples.name}"
        )

    def _set_chunk_nr(self) \
            -> None:
        """
        Sets the chunk number for the chunk checkpoint name.

        The iterator counter of the chunker corresponds to the number of the
        queries it has taken from the queries dictionary.

        """

        self.chunk_nr = int(self.iterator_counter / self.chunk_size)

    def _get_chunk_samples(self, chunk: PromptsDictType) \
            -> MyDataFrame:
        """
        Loads an existing chunk_samples MyDataFrame object or creates it.

        Parameters
        ----------
        chunk : PromptsDictType
            The current chunk.

        Returns
        -------

        """
        chunk_samples_name = f"{self._samples.name}_chunk_{self.chunk_nr}"

        # Create an empty MyDataFrame with the chunk samples name
        my_df = MyDataFrameFactory.create(name=chunk_samples_name)

        # Use csv format instead of the default pkl format for (My)DataFrames
        # to be able to open the file with MSExcel.
        my_df.file_type = 'csv'

        # Try to find and load an existing MyDataFrame with this name
        if my_df.can_load():
            my_df.load()
            return my_df

        # Otherwise fill the MydataFrame based on the samples property of
        # this class by using the query parts contained in the chunk.
        return self._add_query_cols(my_df, chunk)

    def _add_query_cols(
            self,
            my_df: MyDataFrame,
            chunk: PromptsDictType
    ) -> MyDataFrame:
        """
        Creates the chunk samples.

        Fills the provided empty MyDataFrame with the samples with which this
        class was initialized and the query columns composed from the prompt
        parts in the provided chunk.

        Calls the PromptEngineer initialized when the ChunkProcessor itself
        was initialized to perform this prompt engineering strategy-specific
        task.

        Parameters
        ----------
        my_df : MyDataFrame
            The provided empty MyDataFrame, which has already been assigned
            the correct name attribute for its serialization.

        chunk : PromptsDictType
            The current chunk that was returned by the queries chunker,
            containing the prompt parts from which to build the queries for
            the samples in the current batch.

        Returns
        -------
        MyDataFrame
            The provided MyDataFrame object with the batch samples and
            different query columns added.

        """

        df = self._samples.df.copy()

        my_df.df = self.prompt_engineer.add_query_cols(df, chunk)

        return my_df

    # endregion --- Protected Methods
